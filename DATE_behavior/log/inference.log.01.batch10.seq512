DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 32332
    })
})
{'id': '0', 'translation': {'en': 'Source: Project Gutenberg', 'it': 'Source: www.liberliber.it/Audiobook available here'}}
{'en': 'Source: Project Gutenberg', 'it': 'Source: www.liberliber.it/Audiobook available here'}
Source: Project Gutenberg
<class 'dict'>
{'en': 'Source: Project Gutenberg', 'it': 'Source: www.liberliber.it/Audiobook available here'}
tokenized_datasets ---->>
{'input_ids': tensor([[  101,  3120,  1024,  ...,     0,     0,     0],
        [  101,  4869, 26975,  ...,     0,     0,     0],
        [  101,  5904, 22953,  ...,     0,     0,     0],
        ...,
        [  101,  1996,  2056,  ...,     0,     0,     0],
        [  101,  2033,  1010,  ...,     0,     0,     0],
        [  101,  1000,  2054,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])}
torch.Size([10, 512])
torch.Size([10, 512])
torch.Size([10, 512])
tensor(29566)
x.shape
torch.Size([10, 512, 768])
input embedding write: 
tensor([[[-0.4693,  0.2721, -0.8470,  ...,  0.6290, -1.6237,  0.0000],
         [ 1.5712,  0.4274,  0.5956,  ...,  1.2555, -1.1557, -0.3068],
         [-0.3835,  0.6275,  0.9270,  ...,  0.7437, -1.0113, -0.1667],
         ...,
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -0.0000],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415]],

        [[-0.0000,  0.2721, -0.8470,  ...,  0.6290, -1.6237,  0.4922],
         [ 0.4830,  0.5868,  0.8677,  ...,  0.0000, -0.8956, -1.8522],
         [ 0.5287, -0.5853,  0.9678,  ..., -0.1954, -1.5474,  0.5787],
         ...,
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -0.0000],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.0000, -1.9415]],

        [[-0.4693,  0.2721, -0.8470,  ...,  0.6290, -1.6237,  0.4922],
         [-0.9637, -2.7340,  2.5624,  ...,  0.0000,  0.1472, -2.0090],
         [ 0.8144,  0.0000, -0.5105,  ..., -1.1793,  0.8262,  0.2226],
         ...,
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415]],

        ...,

        [[-0.4693,  0.2721, -0.8470,  ...,  0.6290, -1.6237,  0.4922],
         [ 0.8698,  1.1492, -0.2716,  ..., -0.6180, -0.9817,  0.4784],
         [-0.9321, -2.7314, -1.4937,  ..., -0.7767,  2.0884, -1.1922],
         ...,
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -0.0000],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415]],

        [[-0.4693,  0.2721, -0.8470,  ...,  0.6290, -1.6237,  0.4922],
         [-0.8509, -1.2078, -1.9997,  ...,  0.5238,  0.4692, -0.6649],
         [ 0.9977, -0.0000, -0.2378,  ...,  0.8162, -0.8371, -0.0000],
         ...,
         [ 0.5976,  1.4377,  1.7567,  ...,  0.0000, -0.3167, -1.9415],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -1.9415],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.0000, -1.9415]],

        [[-0.4693,  0.2721, -0.8470,  ...,  0.6290, -1.6237,  0.0000],
         [ 2.4023,  1.7068,  1.9271,  ..., -1.6183,  1.0683,  2.8619],
         [-0.4808,  0.4942, -0.0000,  ...,  0.1737,  0.0090, -1.3273],
         ...,
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -0.0000],
         [ 0.5976,  1.4377,  1.7567,  ...,  2.5673, -0.3167, -0.0000],
         [ 0.5976,  0.0000,  1.7567,  ...,  2.5673, -0.3167, -1.9415]]],
       grad_fn=<MulBackward0>)
input_ids have 872 tokens
word embedding token fetch output: latency=872, energy=872
lat,en: cap_in_write output after writing x and pe
16232 16232
lat,en: add_cap_to_fet: output after adding x and pe and writing xpe
23912 23912
lat,en: after writing xpe in FET
31592 31592
w_q.weight
Parameter containing:
tensor([[ 0.0206, -0.0205, -0.0330,  ...,  0.0222, -0.0297, -0.0173],
        [ 0.0193,  0.0237,  0.0184,  ...,  0.0099, -0.0288,  0.0111],
        [ 0.0135,  0.0208, -0.0091,  ...,  0.0155, -0.0099, -0.0119],
        ...,
        [-0.0195,  0.0210, -0.0078,  ...,  0.0052,  0.0165,  0.0214],
        [-0.0307,  0.0116,  0.0196,  ...,  0.0151,  0.0185, -0.0079],
        [-0.0111, -0.0022,  0.0008,  ..., -0.0271, -0.0337, -0.0317]],
       requires_grad=True)
w_q.shape
torch.Size([768, 768])
lat,en: fet mac output compute q,k,v
16986962792.0 16986962792.0
query.shape
torch.Size([10, 512, 768])
query.shape
torch.Size([10, 12, 512, 64])
lat,en: after cap_bl_to_sa_wr_rm: q,k,v write
16986985832.0 16986985832.0
lat,en: after qkt mac computation
20761859432.0 20761859432.0
attention_scores.shape
torch.Size([10, 12, 512, 512])
qk_t write output: lat,en
20761920872.0 20761920872.0
softmax output: lat,en
21013579112.0 21013579112.0
attention_scores.shape
torch.Size([10, 12, 512, 512])
qkt*v output: lat,en
51212567912.0 51212567912.0
attention_matrix.shape
torch.Size([10, 12, 512, 64])
after writing soft(qkt)*v
51212575592.0 51212575592.0
MHA output lat,en results
56874885992.0 56874885992.0
attention_matrix.shape
torch.Size([10, 512, 768])
After writing MHA output to the FET: lat,en
56874893672.0 56874893672.0
add_dram: lat,en
56906350952.0 56906350952.0
layernorm output1 shape:
torch.Size([10, 512, 768])
after writing the output of the x+mha_output in the fet: lat,en
56906358632.0 56906358632.0
ff1 layer output shape:
torch.Size([10, 512, 3072])
ff1 mac output: lat,en
79555600232.0 79555600232.0
ff1 mac output FET write: lat,en
79555630952.0 79555630952.0
ff_relu shape:
torch.Size([10, 512, 3072])
FF2 mac operation output: lat,en
102204872552.0 102204872552.0
ff2 mac output FET write: lat,en
102204880232.0 102204880232.0
ff_out.shape
torch.Size([10, 512, 768])
torch.Size([10, 512, 768])
Encoder layer output: add_dram x+ff2 : lat,en
102236337512.0 102236337512.0
Encoder output write FET: lat,en
102236345192.0 102236345192.0
Encoder layer output shape:
torch.Size([10, 512, 768])
input_ids
tensor([[  101,  3120,  1024,  ...,     0,     0,     0],
        [  101,  4869, 26975,  ...,     0,     0,     0],
        [  101,  5904, 22953,  ...,     0,     0,     0],
        ...,
        [  101,  1996,  2056,  ...,     0,     0,     0],
        [  101,  2033,  1010,  ...,     0,     0,     0],
        [  101,  1000,  2054,  ...,     0,     0,     0]])
torch.Size([10, 512])
lat_before_mha,lat_after_mha,lat_after_encoder
31592 56874885992.0 102236345192.0
en_before_mha,en_after_mha,en_after_encoder
31592 56874885992.0 102236345192.0
end_to_end_latency is 601212396392.0 and end_to_end_energy is 1226835794792.0
